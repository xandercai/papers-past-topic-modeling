{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Data Wrangling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.name', 'local'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.app.id', 'local-1547703148161'),\n",
      " ('spark.driver.host', '192.168.1.207'),\n",
      " ('spark.driver.memory', '62g'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.driver.port', '33743'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.ui.showConsoleProgress', 'true'),\n",
      " ('spark.driver.cores', '6'),\n",
      " ('spark.driver.maxResultSize', '4g')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=local>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "sys.path.insert(0, '../utils') # for import customed modules\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from utils_data import conf_pyspark, load_dataset\n",
    "\n",
    "# intiate PySpark\n",
    "sc, spark = conf_pyspark()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load raw dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16731578, 6)\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|16318264|http://api.digita...|Poverty Bay Herald|1915-08-05T00:00:...|Poverty Bay Heral...|Poverty Bay Heral...|\n",
      "| 2405275|http://api.digita...|      Bruce Herald|1877-12-18T00:00:...|Clutha County Cou...|Clutha County Cou...|\n",
      "| 3101410|http://api.digita...| Ohinemuri Gazette|1898-08-24T00:00:...|Page 2 Advertisem...|X For coughs aud ...|\n",
      "| 6263657|http://api.digita...| Ohinemuri Gazette|1912-12-02T00:00:...|THE WAR IN EUROPE...|THE WAR IN EUROPE...|\n",
      "| 6308684|http://api.digita...| Ohinemuri Gazette|1912-03-29T00:00:...|CHAMPION OF CHAMP...|\"CHAMPION OF CHAM...|\n",
      "| 4770113|http://api.digita...|          NZ Truth|1917-06-23T00:00:...|Untitled (NZ Trut...|Lord UUuWUotu* ii...|\n",
      "|11559016|http://api.digita...|   Southland Times|1896-01-07T00:00:...|Page 3 Advertisem...|N.Z Loan Co. MALD...|\n",
      "|12158330|http://api.digita...|   Southland Times|1900-05-25T00:00:...|The Dairy Associa...|The Dairy Associa...|\n",
      "|12561345|http://api.digita...|   Southland Times|1902-02-05T00:00:...|The Valdares (Sou...|b\"The ValdaresThe...|\n",
      "|12390162|http://api.digita...|   Southland Times|1901-10-07T00:00:...|The Best Remedy f...|b'The Best Remedy...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('papers_past', spark)\n",
    "\n",
    "nrow_raw = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow_raw, len(df.columns)))\n",
    "df.sample(False, 0.00001).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|  56232|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows with empty document:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NA to avoid nonetype.\n",
    "df = df.na.drop(subset=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|      0|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"id\" should be unique, check duplication:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  543700\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are duplicated \"id\" in the dataset, show three of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|      id|count|\n",
      "+--------+-----+\n",
      "|10036037|    2|\n",
      "|10059447|    2|\n",
      "|10099968|    2|\n",
      "+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id').count().where(F.col('count')>1).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the first one to check detail:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id == 10036037).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check difference of the content:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.9994846688997681\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = df.filter(df.id == 10036037).select('content').collect()[0]['content']\n",
    "#print(str1 + '\\n')\n",
    "\n",
    "str2 = df.filter(df.id == 10036037).select('content').collect()[1]['content']\n",
    "#print(str2 + '\\n')\n",
    "\n",
    "diff = difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "print('Similarity: ', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The two duplicates are very close, drop one of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check duplicate again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  0\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Abnormal Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There should be 68 publishers, check numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "Correct! no abnormal values in publishers.\n"
     ]
    }
   ],
   "source": [
    "n = df.select('publisher').distinct().count()\n",
    "print(n)\n",
    "if n == 68:\n",
    "    print('Correct! no abnormal values in publishers.')\n",
    "else:\n",
    "    print('Error! abnormal values in publishers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For history documents, it only need date as time unit, we extract \"date\" column from \"time\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature date\n",
    "df = df.withColumn('date', df['time'].cast(DateType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check schema of the dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check date range has abnormal values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1839, 8, 21), datetime.date(1945, 12, 31))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = df.select(F.min('date'), F.max('date')).first()\n",
    "start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check \"title\" column to see if it is possible to extract features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------------------------------------------------+\n",
      "|id      |date      |title                                                       |\n",
      "+--------+----------+------------------------------------------------------------+\n",
      "|33583964|1901-08-17|TELEGRAMS. (Otago Daily Times 17-8-1901)                    |\n",
      "|6577219 |1901-03-25|AN UNFORTUNATE MISTAKE. (Bay Of Plenty Times, 25 March 1901)|\n",
      "|28322435|1893-04-07|CARNEGIE'S EMPLOYEES. (Auckland Star, 07 April 1893)        |\n",
      "|13133895|1902-06-06|Telegraphic News. (Thames Star, 06 June 1902)               |\n",
      "|18336280|1927-05-03|Page 14 Advertisements Column 2 (Evening Post, 03 May 1927) |\n",
      "|2918534 |1862-11-18|WATER SUPPLY. (Otago Daily Times, 18 November 1862)         |\n",
      "|28183893|1890-07-25|TELEGRAPHIC\" SHIPPING. (Auckland Star, 25 July 1890)        |\n",
      "|7228753 |1883-01-06|Gossipy Paragraphs. (Otago Witness, 06 January 1883)        |\n",
      "|16698477|1918-09-07|THE BATTIE FRONT. (Poverty Bay Herald, 07 September 1918)   |\n",
      "|2811594 |1884-01-21|HOPS. (Colonist, 21 January 1884)                           |\n",
      "+--------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'date', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"title\" column specified advertisement, we extract \"ads\" column from \"title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id      |ads  |title                                                                                                                                                                                                                         |\n",
      "+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|7929407 |false|FOREIGN & COLONIAL TELEGRAMS. (Timaru Herald, 01 November 1883)                                                                                                                                                               |\n",
      "|23559405|false|IN THE AIR. (Feilding Star, 17 March 1911)                                                                                                                                                                                    |\n",
      "|24126997|false|INTERCOLONIAL. (Otago Daily Times, 05 November 1898)                                                                                                                                                                          |\n",
      "|4186376 |true |Page 1 Advertisements Column 4 (Feilding Star, 10 March 1894)                                                                                                                                                                 |\n",
      "|5697124 |false|COMMERCIAL INTELLIGENCE.  COMMERCIAL TELEGRAMS.  (PER ARAWATA- UNDATED.)  Melbourne.  New teas are selling at full rates. Sugar advanced. Oats 5s 2d.  (PER PRESS AGENCY.)  Timaru, July 22. (North Otago Times, 23 July 1878)|\n",
      "|24302575|false|ATHLETE AND M.P. (Hawera & Normanby Star, 09 December 1913)                                                                                                                                                                   |\n",
      "|3090856 |false|SOLICITOR'S OPINION. (Otago Witness, 03 February 1855)                                                                                                                                                                        |\n",
      "|15044388|true |Page 1 Advertisements Column 4 (Colonist, 29 May 1909)                                                                                                                                                                        |\n",
      "|8820843 |true |Page 4 Advertisements Column 2 (Tuapeka Times, 10 April 1909)                                                                                                                                                                 |\n",
      "|13013025|false|POSTAL NOTICES. (West Coast Times, 21 May 1900)                                                                                                                                                                               |\n",
      "+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract feature ads\n",
    "df = df.withColumn('ads', df.title.contains('dvertisement'))\n",
    "\n",
    "df.sample(False, 0.00001).limit(10).select('id', 'ads', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The title consists of three parts: \"real title\" (\"publisher\", \"date\"), we only need \"real title\" part. Extract real title:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redandunt parts of title\n",
    "df = df.withColumn('title_', F.regexp_extract(F.col('title'), '(.*)(\\s\\(.*\\))', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if some titles are not the form \"title (\"publisher\", \"date\"), which will lead to \"title_\" column is empty string:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------------------+\n",
      "|id      |title_|title                |\n",
      "+--------+------+---------------------+\n",
      "|3656781 |      |Untitled Illustration|\n",
      "|4832017 |      |Untitled Illustration|\n",
      "|5417742 |      |Untitled Illustration|\n",
      "|12676570|      |Untitled Illustration|\n",
      "|12777321|      |Untitled Illustration|\n",
      "+--------+------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(F.col('title_') == '').select(['id', 'title_', 'title']).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change empty string in \"title_\" column to \"Untitled Illustration\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'title_',\n",
    "    F.when(\n",
    "        F.col('title_') == '',\n",
    "        F.lit('Untitled Illustration')\n",
    "    ).otherwise(\n",
    "        F.col('title_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty string again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "| id|url|publisher|time|title|content|date|ads|title_|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "|  0|  0|        0|   0|    0|      0|   0|  0|     0|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print title columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|id      |title_                                                          |title                                                                                            |\n",
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|20077538|FOURTEEN VESSELS                                                |FOURTEEN VESSELS (Evening Post, 29 September 1941)                                               |\n",
      "|32535786|CABLE MESSAGES                                                  |CABLE MESSAGES (Otago Daily Times 2-12-1910)                                                     |\n",
      "|10261389|AUSTRALIAN. SYDNEY UNDER A CLOUD. HARVEST PROSPECTS IN VICTORIA.|AUSTRALIAN. SYDNEY UNDER A CLOUD. HARVEST PROSPECTS IN VICTORIA. (Evening Post, 26 November 1888)|\n",
      "|3595355 |Page 1 Advertisements Column 3                                  |Page 1 Advertisements Column 3 (Bruce Herald, 29 February 1884)                                  |\n",
      "|26658773|SCIENTIFIC AND INDUSTRIAL RESEARCH.                             |SCIENTIFIC AND INDUSTRIAL RESEARCH. (Colonist, 04 December 1916)                                 |\n",
      "|2723654 |Page 6 Advertisements Column 1                                  |Page 6 Advertisements Column 1 (Ohinemuri Gazette, 16 July 1892)                                 |\n",
      "|26143279|Page 7 Advertisements Column 4                                  |Page 7 Advertisements Column 4 (Wanganui Chronicle, 24 November 1913)                            |\n",
      "|2437244 |Page 8 Advertisements Column 1                                  |Page 8 Advertisements Column 1 (Bruce Herald, 24 September 1878)                                 |\n",
      "|11818337|CABLE BREVITIES.                                                |CABLE BREVITIES. (Thames Star, 30 March 1899)                                                    |\n",
      "|26864072|SCENIC DESTRUCTION.                                             |SCENIC DESTRUCTION. (Northern Advocate, 21 November 1910)                                        |\n",
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'title_', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the website of [Papers Past](https://paperspast.natlib.govt.nz), we could find the publisher-region relationship in the [Explore all newspapers](https://paperspast.natlib.govt.nz/newspapers/all#region) webpage. Based on this webpage, we could extract region feature from \"publisher\" column. Here we saved [the webpage](https://paperspast.natlib.govt.nz/newspapers/all#region) and crawling the publisher-region relationship into a dataframe for extract feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# read webpage\n",
    "path = r'../temp/Papers Past _ Explore all newspapers.html'\n",
    "with open(path, 'r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "# get table \n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.find('table', attrs={'class':'table datatable'})\n",
    "table_rows = table.find_all('tr')\n",
    "res = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "    if row:\n",
    "        res.append(row)\n",
    "\n",
    "# transform table to pandas dataframe\n",
    "df_region = pd.DataFrame(res, columns=['publisher_', 'region', 'start_', 'end_']) # column_ means it will be drop later\n",
    "\n",
    "# transform pandas dataframe to pyspark dataframe\n",
    "df_region = spark.createDataFrame(df_region).orderBy('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (148, 4)\n",
      "+-------------------+-----------------+------+----+\n",
      "|publisher_         |region           |start_|end_|\n",
      "+-------------------+-----------------+------+----+\n",
      "|Albertland Gazette |Auckland         |1862  |1864|\n",
      "|Hot Lakes Chronicle|Bay of Plenty    |1895  |1910|\n",
      "|Ashburton Guardian |Canterbury       |1879  |1921|\n",
      "|Ellesmere Guardian |Canterbury       |1891  |1945|\n",
      "|Globe              |Canterbury       |1874  |1882|\n",
      "|Matariki           |Gisborne         |1881  |1881|\n",
      "|Feilding Star      |Manawatu-Wanganui|1882  |1920|\n",
      "|Nelson Evening Mail|Nelson           |1866  |1922|\n",
      "|Bruce Herald       |Otago            |1865  |1920|\n",
      "|Lake County Press  |Otago            |1872  |1928|\n",
      "+-------------------+-----------------+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataframe: ({}, {})'.format(df_region.count(), len(df_region.columns)))\n",
    "df_region.sample(False, 0.1).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that in this publisher-region relationship dataframe, there are two publisher's name is not identical with the dataset: \"Bay Of Plenty Times\" mismatch by \"of\", \"New Zealand Free Lance\" mismatch by \"New Zeland\", so we modify the** `df_region` **to make it identical with dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------+----+\n",
      "|publisher_         |region       |start_|end_|\n",
      "+-------------------+-------------+------+----+\n",
      "|Bay of Plenty Times|Bay of Plenty|1872  |1949|\n",
      "|Free Lance         |Wellington   |1900  |1920|\n",
      "+-------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df_region for Bay Of Plenty Times and New Zealand Free Lance\n",
    "df_region = df_region.withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Bay of Plenty Times',\n",
    "        F.lit('Bay Of Plenty Times')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ").withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Free Lance',\n",
    "        F.lit('New Zealand Free Lance')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if the two publishers' name were modified:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+------+----+\n",
      "|publisher_            |region       |start_|end_|\n",
      "+----------------------+-------------+------+----+\n",
      "|Bay Of Plenty Times   |Bay of Plenty|1872  |1949|\n",
      "|New Zealand Free Lance|Wellington   |1900  |1920|\n",
      "+----------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay Of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'New Zealand Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the dataframe for later use:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../temp/region.csv'\n",
    "\n",
    "(df_region.select(F.col('publisher_'),\n",
    "                  F.col('region'))\n",
    " .toPandas()\n",
    " .to_csv(path, header=False, index=False, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract region column, and abandon redundant columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.join(df_region, df.publisher == df_region.publisher_, how='left')\n",
    "      .select(F.col('id'), \n",
    "              F.col('publisher'), \n",
    "              F.col('region'), \n",
    "              F.col('date'), \n",
    "              F.col('ads'), \n",
    "              F.col('title_').alias('title'), \n",
    "              F.col('content'))\n",
    "      .orderBy('id')\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing missing value in region column with \"unknwon\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill({'region':'unknown'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if miss any field or element:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null and empty string:\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "| id|publisher|region|date|ads|title|content|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "|  0|        0|     0|   0|  0|    0|      0|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print Null and empty string:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check dataframe szie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16131646, 7)\n",
      "usable line percentage: 0.9641437287026962\n",
      "removed line number: 599932\n"
     ]
    }
   ],
   "source": [
    "nrow = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow, len(df.columns)))\n",
    "print('usable line percentage:', nrow/nrow_raw)\n",
    "print('removed line number:', nrow_raw - nrow)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After data wrangling, there are:**\n",
    "* 16,131,646 (96.4%) samples/rows/lines/documents usable, \n",
    "* 599,932 samples/rows/lines/documents were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print schema and dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- region: string (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- ads: boolean (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|     id|           publisher|           region|      date|  ads|               title|             content|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|1948954|       Clutha Leader|            Otago|1876-10-27|false|SATURDAY, OCTOBER...|SATURDAY, OCTOBER...|\n",
      "|2255241|    Grey River Argus|       West Coast|1869-10-30| true|Page 1 Advertisem...|TJOUNDABY TIMBER ...|\n",
      "|2703510|New Zealand Gazet...|       Wellington|1842-08-13| true|Page 4 Advertisem...|! Heifers in Calf...|\n",
      "|3143807|Daily Southern Cross|         Auckland|1863-10-24|false|QUEEN'S REDOUBT. ...|QUEEN'S REDOUBT. ...|\n",
      "|3358839|       Te Aroha News|          Waikato|1887-06-04|false|THE CALIFORNIAN S...|THE CALIFORNIAN S...|\n",
      "|3431907|            Colonist|           Nelson|1859-11-15|false|     COPPER COINAGE.|COPPER COINAGE.Wi...|\n",
      "|3482586|Wellington Indepe...|       Wellington|1862-04-11|false|THE AMERICAN BLOC...|THE AMERICAN BLOC...|\n",
      "|3622567|  Wanganui Chronicle|Manawatu-Wanganui|1875-03-10| true|Page 1 Advertisem...|BUSINESS CARDS. W...|\n",
      "|3785597|     Wanganui Herald|Manawatu-Wanganui|1877-09-08|false|         COMMERCIAL.|COMMERCIAL.1 'Mes...|\n",
      "|3852255|   Otago Daily Times|            Otago|1863-04-09| true|Page 1 Advertisem...|Shipping Notice. ...|\n",
      "|3982952|     Wanganui Herald|Manawatu-Wanganui|1878-01-14|false|        VERY LATEST.|VERY LATEST.Londo...|\n",
      "|4313773|            Observer|         Auckland|1891-07-04|false|            PARNELL.|PARNELL.Matty, th...|\n",
      "|5002349|  Wanganui Chronicle|Manawatu-Wanganui|1878-07-29|false|       CHRISTCHURCH.|CHRISTCHURCH.,Â„y ...|\n",
      "|5280288|         Thames Star|          Waikato|1878-10-10|false|           BLENHEIM.|BLENHEIM., This d...|\n",
      "|5322362| Nelson Evening Mail|           Nelson|1874-08-08|false|BY ELECTRIC TELEG...|BY ELECTRIC TELEG...|\n",
      "|5838766|     Wanganui Herald|Manawatu-Wanganui|1881-05-02| true|Page 4 Advertisem...|b'Business, adver...|\n",
      "|5925320|       Feilding Star|Manawatu-Wanganui|1897-04-27| true|Page 3 Advertisem...|Cash Exchange Co-...|\n",
      "|6078274|     Southland Times|            Otago|1878-01-28|false|  DUNEDIN, Saturday.|DUNEDIN, Saturday...|\n",
      "|6169978|            Observer|         Auckland|1901-09-14| true|Page 23 Advertise...|b'\\xe2\\x80\\xa2gRO...|\n",
      "|6261054|     Wanganui Herald|Manawatu-Wanganui|1882-02-21|false|    THE S.S. WAKATU.|b'THE S.S. WAKATU...|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.sample(False, 0.00001).limit(20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Save Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dataset for Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataframe would be our final dataset to generate metadata and subset to analyze and visualize, let's save it as compressed csv file to save time for later processes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/dataset'\n",
    "df.write.csv(path, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the clean dataset size:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw   dataset size: 33G\n",
      "clean dataset size: 14G\n"
     ]
    }
   ],
   "source": [
    "path = r'../data/papers_past'\n",
    "print('raw   dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))\n",
    "path = r'../data/dataset'\n",
    "print('clean dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After processing and compressing, the dataset reduce from 33GB to 14GB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dataset for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataset would be the full dataset for MALLET topic modeling, we will use this trained topic model to infer topic models of subset to analyze and visualize, the difference between dataset for subset and dataset for training is that dataset for taining contains only three columns (\"id\", \"title\" and \"content\"), because MALLET only take three columns data and take the third column as documents by default.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16131646, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df.select(F.col('id'), F.col('title'), F.col('content'))\n",
    "print('Shape of dataframe: ({}, {})'.format(df.count(), len(df.columns)))\n",
    "\n",
    "path = r'../data/train'\n",
    "df.write.csv(path, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-to-train size: 14G\n"
     ]
    }
   ],
   "source": [
    "path = r'../data/train'\n",
    "print('dataset-to-train size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
