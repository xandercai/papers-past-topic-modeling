{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.2 - Topic Modeling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 14:19:55\n"
     ]
    }
   ],
   "source": [
    "import gc, subprocess\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "import datetime\n",
    "print (datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this part, we will perform following operations:**\n",
    "\n",
    "1. using MALLET to train the training set, getting a topic model and topic modeling result files;\n",
    "1. inferring subsets, getting inferring result files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We do not think of the number of topics as a natural characteristic of corpora. The topic number is not really combinations of multinomial distributions, so there is no \"right\" topic number. We think of the number of topics as the scale of a map of corpora. If we want a broad overview, we use a small topic number. If we want more detail, use a larger topic number. The right number is the value that produces meaningful results that allow us to accomplish our goal.**\n",
    "\n",
    "**There is a wide range of good values for us, here we will train the dataset to get a topic model with 200 topics.**\n",
    "\n",
    "**Many metric methods and tools could help us to quantitatively tune the topic number,  such as [Hierarchical Dirichlet process](https://en.wikipedia.org/wiki/Hierarchical_Dirichlet_process), [ldatuning](https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html) and [topic coherence](https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/), those evaluate work could be our future work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**LDA**\n",
    ">\n",
    ">Latent Dirichlet Allocation, is an unsupervised generative model that assigns topic distributions to documents.\n",
    ">\n",
    ">At a high level, the model assumes that each document will contain several topics, so that there is topic overlap within a document. The words in each document contribute to these topics. The topics may not be known a priori, and needn't even be specified, but the **number** of topics must be specified a priori. Finally, there can be words overlap between topics, so several topics may share the same words.\n",
    ">\n",
    ">The model generates to **latent** (hidden) variables\n",
    ">1. A distribution over topics for each document\n",
    ">2. A distribution over words for each topics\n",
    ">\n",
    ">After training, each document will have a discrete distribution over all topics, and each topic will have a discrete distribution over all words.\n",
    ">\n",
    ">It is best to demonstrate this with an example. Let's say a document about the presidential elections may have a high contribution from the topics \"presidential elections\", \"america\", \"voting\" but have very low contributions from topics \"himalayan mountain range\", \"video games\", \"machine learning\" (assuming the corpus is varied enough to contain such articles); the topics \"presidential elections\" may have top contributing words [\"vote\", \"election\", \"people\", \"usa\", \"clinton\", \"trump\", ...] whereas the top contributing words in the topic \"himalayan mountain range\" may be [\"nepal\", \"everest\", \"china\", \"altitude\", \"river\", \"snow\", ...]. This very rough example should give you an idea of what LDA aims to do.\n",
    ">\n",
    ">An important point to note: although I have named some topics in the example above, the model itself does not actually do any \"naming\" or classifying of topics. But by visually inspecting the top contributing words of a topic i.e. the discrete distribution over words for a topic, one can name the topics if necessary after training. We will show this more later.\n",
    ">\n",
    ">There a several ways to implement LDA, however I will speak about collapsed gibbs sampling as I usually find this to be the easiest way to understand it.\n",
    ">\n",
    ">The model initialises by assigning every word in every document to a **random** topic. Then, we iterate through each word, unassign it's current topic, decrement the topic count corpus wide and reassign the word to a new topic based on the local probability of topic assignemnts to the current document, and the global (corpus wide) probability of the word assignments to the current topic. This may be hard to understand in words, so the equations are below.\n",
    ">\n",
    ">**The mathematics of collapsed gibbs sampling (cut back version)**\n",
    ">\n",
    ">Recall that when we iterate through each word in each document, we unassign its current topic assignment and reassign the word to a new topic. The topic we reassign the word to is based on the probabilities below.\n",
    ">\n",
    ">$$\n",
    ">P\\left(\\text{document \"likes\" the topic}\\right) \\times P\\left(\\text{topic \"likes\" the word } w'\\right)\n",
    ">$$\n",
    ">\n",
    ">$$\n",
    ">\\Rightarrow \\frac{n_{i,k}+\\alpha}{N_i-1+K\\alpha} \\times \\frac{m_{w',k}+\\gamma}{\\sum_{w\\in V}m_{w,k} + V\\gamma}\n",
    ">$$\n",
    ">\n",
    ">where\n",
    ">\n",
    ">$n_{i,k}$ - number of word assignments to topic $k$ in document $i$\n",
    ">\n",
    ">$n_{i,k}$ - number of assignments to topic $k$ in document $i$\n",
    ">\n",
    ">$\\alpha$ - smoothing parameter (hyper parameter - make sure probability is never 0)\n",
    ">\n",
    ">$N_i$ - number of words in document $i$\n",
    ">\n",
    ">$-1$ - don't count the current word you're on\n",
    ">\n",
    ">$K$ - total number of topics\n",
    ">\n",
    ">\n",
    ">$m_{w',k}$ - number of assignments, corpus wide, of word $w'$ to topic $k$\n",
    ">\n",
    ">$m_{w',k}$ - number of assignments, corpus wide, of word $w'$ to topic $k$\n",
    ">\n",
    ">$\\gamma$ - smoothing parameter (hyper parameter - make sure probability is never 0)\n",
    ">\n",
    ">$\\sum_{w\\in V}m_{w,k}$ - sum over all words in vocabulary currently assigned to topic $k$\n",
    ">\n",
    ">$V$ size of vocabulary i.e. number of distinct words corpus wide\n",
    ">\n",
    ">**Notes and Uses of LDA**\n",
    ">\n",
    ">LDA has many uses; understanding the different varieties topics in a corpus (obviously), getting a better insight into the type of documents in a corpus (whether they are about news, wikipedia articles, business documents), quantifying the most used / most important words in a corpus, and even document similarity and recommendation.\n",
    ">\n",
    ">LDA does not work well with very short documents, like twitter feeds, as explained here [[1]](https://pdfs.semanticscholar.org/f499/5dc2a4eb901594578e3780a6f33dee02dad1.pdf) [[2]](https://stackoverflow.com/questions/29786985/whats-the-disadvantage-of-lda-for-short-texts), which is why we dropped articles under 40 tokens previously. Very briefly, this is because the model infers parameters from observations and if there are not enough observations (words) in a document, the model performs poorly. For short texts, although yet to be rigoursly tested, it may be best to use a [biterm model](https://pdfs.semanticscholar.org/f499/5dc2a4eb901594578e3780a6f33dee02dad1.pdf).\n",
    ">\n",
    ">Unlike the word2vec algorithm, which performs extremely well with full structured sentences, LDA is a bag of words model, meaning word order in a document doesnt count. This also means that stopwords and rare words should be excluded, so that the model doesnt overcompensate for very frequent words and very rare words, both of which do not contribute to general topics.\n",
    ">\n",
    ">**Hyperparameters**\n",
    ">\n",
    ">LDA has 2 hyperparameters: $\\alpha$ and $\\eta$\n",
    ">\n",
    ">$\\alpha$ - A low value for $\\alpha$ means that documents have only a low number of topics contributing to them. A high value of $\\alpha$ yields the inverse, meaning the documents appear more alike within a corpus.\n",
    ">\n",
    ">$\\eta$ - A low value for $\\eta$ means the topics have a low number of contributing words. A high value of $\\eta$ yields the inverse, meaning topics will have word overlap and appear more alike.\n",
    ">\n",
    ">The values of $\\alpha$ and $\\eta$ really depend on the application, and may need to be tweaked several times before the desired results are found... even then, LDA is non-deterministic since parameters are randomly initialised, so the outcome of any run of the model can never be known in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Training Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since MALLET can take one instance per file or one file one instance per line, the only choice for us is one file one instance per line, we already prepared the .csv file for training at par5.1.**\n",
    "\n",
    "**In practice we use notebook to execute bash command only if the sample set is small (under 10% of total), otherwise we execute command line in linux terminal directly and run the script in the background.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3025602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854213</td>\n",
       "      <td>TO OUR HEADERS.</td>\n",
       "      <td>TO OUR HEADERS.; We have to apologize to our. numerous for the delay which has occurred in ' getting out the first n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854215</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>v-/ .ADVERTISEMENTS. •- I Advertisements will he inserted in the y \\Gazette\\\" at the nominal rate of Threepence for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854221</td>\n",
       "      <td>ORIGINAL POETRY.</td>\n",
       "      <td>ORIGINAL POETRY.:- ' FAREWELL T() ENGLAND./ t . Farewell, to happy England ! . *, , For other lands I roam,' /'• To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854224</td>\n",
       "      <td>OUR OWN RIVER-ORUAWHARO !</td>\n",
       "      <td>OUR OWN RIVER-ORUAWHARO !There was heard a song ou the'chiming sea, A mingled breathing of hopo and glee ; W Voices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Post (within Seven days of date,) to any part of , • Great Britain, New ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854213                 TO OUR HEADERS.   \n",
       "1  1854215  Page 1 Advertisements Column 1   \n",
       "2  1854221                ORIGINAL POETRY.   \n",
       "3  1854224       OUR OWN RIVER-ORUAWHARO !   \n",
       "4  1854232  Page 1 Advertisements Column 1   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  TO OUR HEADERS.; We have to apologize to our. numerous for the delay which has occurred in ' getting out the first n...  \n",
       "1  v-/ .ADVERTISEMENTS. •- I Advertisements will he inserted in the y \\Gazette\\\" at the nominal rate of Threepence for ...  \n",
       "2  ORIGINAL POETRY.:- ' FAREWELL T() ENGLAND./ t . Farewell, to happy England ! . *, , For other lands I roam,' /'• To ...  \n",
       "3  OUR OWN RIVER-ORUAWHARO !There was heard a song ou the'chiming sea, A mingled breathing of hopo and glee ; W Voices ...  \n",
       "4  NOTICE.—This Ne?vspaper may b? sent Free by Post (within Seven days of date,) to any part of , • Great Britain, New ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/train/train.csv'\n",
    "patho = r'../models/train/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'train'\n",
    "#bash ./model.sh -i '../data/dataset/sample/train/train.csv' -o '../models/train/' -p 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(pahto+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output files are:**\n",
    "\n",
    "1. `topicKeys.txt`: topics words;\n",
    "1. `topicKeys.txt`: topics distribution per document;\n",
    "1. `inferencer.model`: topic inferencer for inferring subset;\n",
    "1. `stat.gz`corpus that topics belong to;\n",
    "1. `diagnostics.xml`: statistic info;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Inferring Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Except analyze and visualize topic model of training dataset, based on typical application scenario, we could extract several subsets from the training dataset to focus on specific point or features. We infer subset by inferencer to get doc-topic matrix to analyze and visualize topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 By Range of Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 567878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3024444</td>\n",
       "      <td>The New Year.</td>\n",
       "      <td>The New Year.My Dear People,—-----t Although, the close of another civil year means little to us from a Church point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3025052</td>\n",
       "      <td>S. Augustine's, Napier.</td>\n",
       "      <td>S. Augustine's, Napier.Vicar: Rev. Canon Tuke. Curate : Rev. C. L. Wilson. The Dawn of Day. has arrived at last and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3026223</td>\n",
       "      <td>Tolago Bay.</td>\n",
       "      <td>Tolago Bay.Vicar: Rev. O. W. Davidson. The great effort to raise a substantial building fund is to take place on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3026372</td>\n",
       "      <td>P. &amp; O. S.S. Morea.</td>\n",
       "      <td>P. &amp; O. S.S. Morea.My Dear People, I should like to take the opportunity of thanking the many friends who sent us su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3026678</td>\n",
       "      <td>BISHOP'S PRIZES.</td>\n",
       "      <td>BISHOP'S PRIZES.The following have been awarded Bishop's Prizes : — Sunday. Schools.— Senior : None. Junior: 1, Kath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                        1  \\\n",
       "0  3024444            The New Year.   \n",
       "1  3025052  S. Augustine's, Napier.   \n",
       "2  3026223              Tolago Bay.   \n",
       "3  3026372      P. & O. S.S. Morea.   \n",
       "4  3026678         BISHOP'S PRIZES.   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  The New Year.My Dear People,—-----t Although, the close of another civil year means little to us from a Church point...  \n",
       "1  S. Augustine's, Napier.Vicar: Rev. Canon Tuke. Curate : Rev. C. L. Wilson. The Dawn of Day. has arrived at last and ...  \n",
       "2  Tolago Bay.Vicar: Rev. O. W. Davidson. The great effort to raise a substantial building fund is to take place on the...  \n",
       "3  P. & O. S.S. Morea.My Dear People, I should like to take the opportunity of thanking the many friends who sent us su...  \n",
       "4  BISHOP'S PRIZES.The following have been awarded Bishop's Prizes : — Sunday. Schools.— Senior : None. Junior: 1, Kath...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/wwi/wwi.csv'\n",
    "patho = r'../models/wwi/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 By Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Otago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 374495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1857847</td>\n",
       "      <td>Page 2 Advertisements Column 4</td>\n",
       "      <td>MISCELLANEOUS. TAMES GOODALL, Bread and Fanqy Biscuit Maker, Has much pleasure in informing the inhabitants of Tokom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1857876</td>\n",
       "      <td>THE TELEGRAPH.</td>\n",
       "      <td>THE TELEGRAPH.Jli . lon said that as he understood the chief business of the meeting was over, he would take the opp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1857878</td>\n",
       "      <td>Original Correspondence.</td>\n",
       "      <td>Original Correspondence.Oub Correspondence Column is at all times open to tie temperate discussion of questions of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1857993</td>\n",
       "      <td>Page 1 Advertisements Column 3</td>\n",
       "      <td>jj STALLIONS. j NOTICE TO FARMERS, 'I AND BREEDERS OF DRAUHT HOUSES. | j kffllll^fJll npHE (Imported) PURK |j j&amp;^l^^...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1858007</td>\n",
       "      <td>Markets.</td>\n",
       "      <td>Markets.WHOLESALE. — Adelaide, £32 per ton ; colonial, none — brown, 60s per cwt; crystal, 60s. Tea — £9 to £11 ; ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1857847  Page 2 Advertisements Column 4   \n",
       "1  1857876                  THE TELEGRAPH.   \n",
       "2  1857878        Original Correspondence.   \n",
       "3  1857993  Page 1 Advertisements Column 3   \n",
       "4  1858007                        Markets.   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  MISCELLANEOUS. TAMES GOODALL, Bread and Fanqy Biscuit Maker, Has much pleasure in informing the inhabitants of Tokom...  \n",
       "1  THE TELEGRAPH.Jli . lon said that as he understood the chief business of the meeting was over, he would take the opp...  \n",
       "2  Original Correspondence.Oub Correspondence Column is at all times open to tie temperate discussion of questions of p...  \n",
       "3  jj STALLIONS. j NOTICE TO FARMERS, 'I AND BREEDERS OF DRAUHT HOUSES. | j kffllll^fJll npHE (Imported) PURK |j j&^l^^...  \n",
       "4  Markets.WHOLESALE. — Adelaide, £32 per ton ; colonial, none — brown, 60s per cwt; crystal, 60s. Tea — £9 to £11 ; ha...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/Otago/Otago.csv'\n",
    "patho = r'../models/otago/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Canterbury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 282791\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854361</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>CRICKET[rbotbr's tblegrams— oopyright.]MeLBOURyB, January 1. The return mutch between Shaw and LUly white's Eleven a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854363</td>\n",
       "      <td>THE HOME CRISIS.</td>\n",
       "      <td>THE HOME CRISIS.(KETOIK's TBLIORAWB— COPYRIGHT ]London, Deosraber 30.Mr Chamberlain has arrived m London, and is con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854367</td>\n",
       "      <td>LONDON MARKETS.</td>\n",
       "      <td>LONDON MARKETS.Contois remain at par.New Zealand securities — Four per cent. Inscribed Stock are jQi higher, 9S J A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854372</td>\n",
       "      <td>Page 2 Advertisements Column 4</td>\n",
       "      <td>TltY KIRKPATMOK'S NEW SEASON'S JAM. SPECIAL NOTICE. TTURKPATBICK'S NEW SEASON'S J\\\\. JAM is made from NISLSON G»IoWN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854375</td>\n",
       "      <td>O.J.O. NEW YEAR M4KTISG.</td>\n",
       "      <td>0.J.0. NEW YEAR M4KTISG.Chhistchurch, January 1About 300 people were present at tbe OJ.O. Meeting tt-lay. £4100 paer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854361                         CRICKET   \n",
       "1  1854363                THE HOME CRISIS.   \n",
       "2  1854367                 LONDON MARKETS.   \n",
       "3  1854372  Page 2 Advertisements Column 4   \n",
       "4  1854375        O.J.O. NEW YEAR M4KTISG.   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  CRICKET[rbotbr's tblegrams— oopyright.]MeLBOURyB, January 1. The return mutch between Shaw and LUly white's Eleven a...  \n",
       "1  THE HOME CRISIS.(KETOIK's TBLIORAWB— COPYRIGHT ]London, Deosraber 30.Mr Chamberlain has arrived m London, and is con...  \n",
       "2  LONDON MARKETS.Contois remain at par.New Zealand securities — Four per cent. Inscribed Stock are jQi higher, 9S J A ...  \n",
       "3  TltY KIRKPATMOK'S NEW SEASON'S JAM. SPECIAL NOTICE. TTURKPATBICK'S NEW SEASON'S J\\\\. JAM is made from NISLSON G»IoWN...  \n",
       "4  0.J.0. NEW YEAR M4KTISG.Chhistchurch, January 1About 300 people were present at tbe OJ.O. Meeting tt-lay. £4100 paer...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/Canterbury/Canterbury.csv'\n",
    "patho = r'../models/canterbury/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Manawatu-Wanganui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 344669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1891145</td>\n",
       "      <td>MARRIAGE.</td>\n",
       "      <td>b\\MARRIAGE.T^mon\\\\xe2\\\\x80\\\\x94 WHfTsi'H'-i- ofa \\\\xe2\\\\x80\\\\xa2 tW ' i 9(h -Se'pi' \\\\xe2\\\\x96\\\\xa0 tetriber, at All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1891249</td>\n",
       "      <td>PATEA.</td>\n",
       "      <td>b\\PATEA.! :'\\\\xe2\\\\x96\\\\xa0'\\\\xe2\\\\x96\\\\xa0 fir.! Sfept^mbyrl9. The steamer Wakatu, in entering the J&gt; Wver this aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1891282</td>\n",
       "      <td>SHOCKING DEATH.</td>\n",
       "      <td>b'SH OCKING DEAT H .i \\\\xe2\\\\x96\\\\xa0\\\\\\xe2\\\\x80\\\\xa2 / \\\"\\\\'W*rinWKi 4 AyH.J ! *\\\\' 1!!1 ;* *\\\" ; , Wellinotpn, Sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1891315</td>\n",
       "      <td>COMMITTEE MEETING.</td>\n",
       "      <td>b\\COMMITTEE ME ETING.; .j A meeting^ JJieidoif mjttete w*s then \\\\xe2\\\\x96\\\\xa0 (eld, jfttfti 'stpgiail Mv k\\\\xc2\\\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1891367</td>\n",
       "      <td>BISMARCHIS HEALTH  DECLINING.</td>\n",
       "      <td>b'BISMARCH IS HEALTH DECLINING., ; ,. | . ; .{-BY..TEI l EattA*H,; \\\\xc2\\\\x84... : -1,.; , .... 1 .. : \\\\xe2\\\\x80\\\\x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                              1  \\\n",
       "0  1891145                      MARRIAGE.   \n",
       "1  1891249                         PATEA.   \n",
       "2  1891282                SHOCKING DEATH.   \n",
       "3  1891315             COMMITTEE MEETING.   \n",
       "4  1891367  BISMARCHIS HEALTH  DECLINING.   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  b\\MARRIAGE.T^mon\\\\xe2\\\\x80\\\\x94 WHfTsi'H'-i- ofa \\\\xe2\\\\x80\\\\xa2 tW ' i 9(h -Se'pi' \\\\xe2\\\\x96\\\\xa0 tetriber, at All...  \n",
       "1  b\\PATEA.! :'\\\\xe2\\\\x96\\\\xa0'\\\\xe2\\\\x96\\\\xa0 fir.! Sfept^mbyrl9. The steamer Wakatu, in entering the J> Wver this aft...  \n",
       "2  b'SH OCKING DEAT H .i \\\\xe2\\\\x96\\\\xa0\\\\\\xe2\\\\x80\\\\xa2 / \\\"\\\\'W*rinWKi 4 AyH.J ! *\\\\' 1!!1 ;* *\\\" ; , Wellinotpn, Sep...  \n",
       "3  b\\COMMITTEE ME ETING.; .j A meeting^ JJieidoif mjttete w*s then \\\\xe2\\\\x96\\\\xa0 (eld, jfttfti 'stpgiail Mv k\\\\xc2\\\\x...  \n",
       "4  b'BISMARCH IS HEALTH DECLINING., ; ,. | . ; .{-BY..TEI l EattA*H,; \\\\xc2\\\\x84... : -1,.; , .... 1 .. : \\\\xe2\\\\x80\\\\x...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/Manawatu-Wanganui/Manawatu-Wanganui.csv'\n",
    "patho = r'../models/manawatu-wanganui/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Wellington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 634731\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2564904</td>\n",
       "      <td>Page 1 Advertisements Column 7</td>\n",
       "      <td>WANTED Known— Your teeth extracted without pain by pure gas (perfectly harmless) at the London Dental Company, corne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2564905</td>\n",
       "      <td>SPORTING.</td>\n",
       "      <td>SPORTING.♦ THE C J.C. SPRING MEETING. [BY TELEGRAPH — PBESS ASSOCIATION.] Christchttkch, 12tli November. At the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564921</td>\n",
       "      <td>COMMERCIAL &amp; FINANCIAL.</td>\n",
       "      <td>COMMERCIAL &amp; FINANCIAL.|_PBBBS ASSOCIATION. J (Keoeived November 14, 9 a.m.) London, 13th November. The following ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2564922</td>\n",
       "      <td>MAIL NOTICES</td>\n",
       "      <td>MAIL NOTICESSubject to necessiiry alterations mails' will close at the Chief Post Office as under :â .Monday, 14th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2564929</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>ITVAVTD ANDERSON &amp; SON, TEA MERCHANTS &amp; FAMILY GROCERS 40, MOLESWORTH-STREET, WELLINGTON. J. &amp; A. WILSON, FUNERAL DI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  2564904  Page 1 Advertisements Column 7   \n",
       "1  2564905                       SPORTING.   \n",
       "2  2564921         COMMERCIAL & FINANCIAL.   \n",
       "3  2564922                    MAIL NOTICES   \n",
       "4  2564929  Page 4 Advertisements Column 1   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  WANTED Known— Your teeth extracted without pain by pure gas (perfectly harmless) at the London Dental Company, corne...  \n",
       "1  SPORTING.♦ THE C J.C. SPRING MEETING. [BY TELEGRAPH — PBESS ASSOCIATION.] Christchttkch, 12tli November. At the thir...  \n",
       "2  COMMERCIAL & FINANCIAL.|_PBBBS ASSOCIATION. J (Keoeived November 14, 9 a.m.) London, 13th November. The following ar...  \n",
       "3  MAIL NOTICESSubject to necessiiry alterations mails' will close at the Chief Post Office as under :â .Monday, 14th...  \n",
       "4  ITVAVTD ANDERSON & SON, TEA MERCHANTS & FAMILY GROCERS 40, MOLESWORTH-STREET, WELLINGTON. J. & A. WILSON, FUNERAL DI...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/Wellington/Wellington.csv'\n",
    "patho = r'../models/wellington/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 By Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 841233\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854215</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>v-/ .ADVERTISEMENTS. •- I Advertisements will he inserted in the y \\Gazette\\\" at the nominal rate of Threepence for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Post (within Seven days of date,) to any part of , • Great Britain, New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854233</td>\n",
       "      <td>Page 1 Advertisements Column 2</td>\n",
       "      <td>TVT-OTR PAPER, Bill Paper, Envelopes _LV Memorandum Books, Pens, Ink, &amp;c., on sale at the \\ Gazette Office.\\\" O-OPE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854245</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—Tim Newspaper may bs sent Free by Post(roithin Seven days of date,) to any part of Great Britain, New Zealan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854264</td>\n",
       "      <td>Page 2 Advertisements Column 1</td>\n",
       "      <td>NOTICE is hereby given that in case the following persons neglectto fulfill1 the Conditions on which all allotments ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854215  Page 1 Advertisements Column 1   \n",
       "1  1854232  Page 1 Advertisements Column 1   \n",
       "2  1854233  Page 1 Advertisements Column 2   \n",
       "3  1854245  Page 1 Advertisements Column 1   \n",
       "4  1854264  Page 2 Advertisements Column 1   \n",
       "\n",
       "                                                                                                                         2  \n",
       "0  v-/ .ADVERTISEMENTS. •- I Advertisements will he inserted in the y \\Gazette\\\" at the nominal rate of Threepence for ...  \n",
       "1  NOTICE.—This Ne?vspaper may b? sent Free by Post (within Seven days of date,) to any part of , • Great Britain, New ...  \n",
       "2  TVT-OTR PAPER, Bill Paper, Envelopes _LV Memorandum Books, Pens, Ink, &c., on sale at the \\ Gazette Office.\\\" O-OPE ...  \n",
       "3  NOTICE.—Tim Newspaper may bs sent Free by Post(roithin Seven days of date,) to any part of Great Britain, New Zealan...  \n",
       "4  NOTICE is hereby given that in case the following persons neglectto fulfill1 the Conditions on which all allotments ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathi = r'../data/dataset/sample/subset/ads/ads.csv'\n",
    "patho = r'../models/ads/'\n",
    "print('Dataset size:', subprocess.check_output(['wc','-l', pathi]).split()[0].decode('utf-8'))\n",
    "pd.read_table(pathi, header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash -s $pathi $patho\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i $1 -o $2 -p 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open(patho+'log.txt', 'w') as f:\n",
    "    f.write(capt.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
